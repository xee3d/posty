# Posty AI 아동 안전 표준

**앱명**: Posty AI
**개발자**: Posty AI
**시행일**: 2025년 10월 21일
**최종 수정일**: 2025년 10월 21일

---

## 1. 개요

Posty AI(이하 "회사")는 모든 사용자, 특히 아동의 안전을 최우선으로 생각합니다. 본 아동 안전 표준은 Posty AI 서비스(이하 "서비스")에서 아동 성적 학대 및 착취(Child Sexual Abuse and Exploitation, CSAE)를 포함한 모든 형태의 아동 학대를 명시적으로 금지하고, 안전한 디지털 환경을 조성하기 위한 회사의 정책과 절차를 규정합니다.

## 2. 적용 범위

본 표준은 Posty AI 서비스를 이용하는 모든 사용자에게 적용되며, 다음을 포함합니다:

- 서비스 내 모든 콘텐츠 생성 및 공유 활동
- 사용자 간 모든 형태의 상호작용
- 서비스와 연동된 모든 외부 플랫폼 활동

## 3. 아동 성적 학대 및 착취(CSAE) 명시적 금지

### 3.1 절대적 금지 사항

회사는 다음 행위를 **명시적이고 절대적으로 금지**합니다:

1. **아동 성적 학대 자료(Child Sexual Abuse Material, CSAM)** 관련 모든 활동
   - CSAM의 생성, 업로드, 저장, 공유, 배포
   - CSAM의 소지, 접근, 열람
   - CSAM 관련 정보의 공유 또는 교환

2. **아동 성적 착취(Child Sexual Exploitation)** 관련 모든 활동
   - 아동을 대상으로 한 성적 유인 행위(grooming)
   - 아동을 대상으로 한 성적 협박 또는 강요
   - 아동의 성적 착취를 목적으로 한 모든 접근 시도

3. **아동 학대 관련 콘텐츠**
   - 아동에 대한 폭력, 학대를 묘사하거나 조장하는 콘텐츠
   - 아동을 성적 대상화하는 모든 형태의 콘텐츠
   - 아동의 안전을 위협하는 모든 콘텐츠

### 3.2 법적 준수

회사는 다음 법률 및 규정을 엄격히 준수합니다:

- 대한민국 「아동·청소년의 성보호에 관한 법률」
- 대한민국 「정보통신망 이용촉진 및 정보보호 등에 관한 법률」
- 미국 「Child Online Protection Act (COPA)」
- 미국 「Children's Internet Protection Act (CIPA)」
- 국제 아동 보호 관련 협약 및 표준
- Google Play 아동 안전 정책
- Apple App Store 아동 안전 지침
- 기타 관련된 모든 국내외 법률 및 규정

## 4. 아동 안전 보호 조치

### 4.1 연령 제한

- 서비스는 만 14세 이상의 사용자를 대상으로 합니다
- 만 14세 미만 아동의 개인정보는 수집하지 않습니다
- 만 14세 미만 사용자가 발견될 경우 즉시 계정을 정지하고 관련 정보를 삭제합니다

### 4.2 콘텐츠 모니터링

회사는 아동 안전을 위해 다음과 같은 조치를 시행합니다:

- AI 기반 콘텐츠 자동 필터링 시스템 운영
- 의심스러운 활동에 대한 자동 탐지 및 차단
- 사용자 신고 기반 검토 시스템 운영
- 정기적인 안전 감사 실시

### 4.3 기술적 보호 조치

- 아동 관련 부적절한 키워드 및 콘텐츠 자동 차단
- 의심스러운 사용자 행동 패턴 감지 및 경고
- 암호화를 통한 개인정보 보호
- 정기적인 보안 업데이트 및 취약점 점검

## 5. 신고 및 대응 절차

### 5.1 신고 방법

사용자는 다음 방법을 통해 아동 안전 관련 우려사항을 신고할 수 있습니다:

1. **앱 내 신고 기능**
   - 각 콘텐츠 또는 사용자 프로필에서 "신고하기" 버튼 사용
   - 신고 카테고리에서 "아동 안전" 선택

2. **이메일 신고**
   - 아동 안전 전담 이메일: childsafety@getposty.com
   - 일반 지원 이메일: getposty@gmail.com

3. **긴급 상황**
   - 즉각적인 위험이 있는 경우: 즉시 현지 법 집행 기관(112, 119)에 신고
   - 회사에도 동시에 신고하여 적절한 조치가 취해질 수 있도록 협조

### 5.2 신고 처리 절차

1. **접수 및 확인** (24시간 이내)
   - 모든 신고는 24시간 이내에 확인 및 접수
   - 긴급 사안은 즉시 처리

2. **조사** (48시간 이내)
   - 전담팀에 의한 신속한 조사 착수
   - 필요시 외부 전문가 자문

3. **조치** (즉시 ~ 72시간 이내)
   - 위반이 확인된 경우 즉각적인 조치 시행
   - 콘텐츠 삭제 및 계정 영구 정지
   - 관련 법 집행 기관에 신고

4. **사후 관리**
   - 신고자에게 처리 결과 통보
   - 재발 방지를 위한 시스템 개선
   - 관련 기록 보존 및 관리

### 5.3 CSAM 발견 시 대응

회사는 CSAM이 발견될 경우 다음 조치를 즉시 시행합니다:

1. 해당 콘텐츠의 즉각적인 삭제 및 접근 차단
2. 관련 계정의 영구 정지
3. 관련 법 집행 기관에 즉시 신고
   - 대한민국: 경찰청 사이버안전국 (182)
   - 미국: National Center for Missing & Exploited Children (NCMEC)
   - 기타 해당 국가의 관련 기관
4. 증거 자료의 안전한 보존
5. 재발 방지를 위한 시스템 강화

## 6. 아동 안전 담당자

회사는 아동 안전 관련 업무를 전담하는 책임자를 지정합니다:

**아동 안전 담당 책임자**
- 직책: 아동 안전 및 신뢰 책임자 (Child Safety & Trust Officer)
- 이메일: childsafety@getposty.com
- 일반 문의: getposty@gmail.com
- 운영시간: 연중무휴 24시간 (긴급 사안 우선 처리)

**담당 업무**
- 아동 안전 정책 수립 및 시행
- 신고 검토 및 대응 총괄
- 법 집행 기관과의 협력
- 아동 안전 관련 교육 및 인식 제고
- 정기적인 안전 감사 및 보고서 작성

## 7. 법 집행 기관 협력

### 7.1 협력 원칙

회사는 아동 보호를 위해 법 집행 기관과 적극적으로 협력합니다:

- 합법적인 정보 요청에 신속히 대응
- CSAM 관련 사건에 대한 자발적 신고
- 수사에 필요한 증거 자료 보존 및 제공
- 국제 협력 프로그램 참여

### 7.2 정보 제공

법 집행 기관의 적법한 요청이 있는 경우, 다음 정보를 제공할 수 있습니다:

- 계정 정보 및 활동 기록
- 위반 콘텐츠 및 메타데이터
- IP 주소 및 접속 기록
- 기타 수사에 필요한 관련 정보

## 8. 사용자 교육 및 인식 제고

### 8.1 안전 가이드 제공

회사는 사용자에게 다음 정보를 제공합니다:

- 아동 온라인 안전 가이드
- 부적절한 콘텐츠 신고 방법
- 디지털 시민의식 교육 자료
- 정기적인 안전 알림 및 업데이트

### 8.2 부모 및 보호자 지원

- 자녀의 온라인 활동 모니터링 가이드
- 연령별 안전 설정 정보
- 위험 신호 인식 방법
- 사건 발생 시 대응 절차

## 9. 위반 시 조치

### 9.1 제재 수준

위반의 심각성에 따라 다음 조치가 적용됩니다:

**Level 1: 경미한 위반**
- 경고 및 콘텐츠 삭제
- 일시적 계정 정지 (1-7일)

**Level 2: 중대한 위반**
- 계정 정지 (30일 이상)
- 서비스 접근 제한

**Level 3: 심각한 위반 (CSAE 관련)**
- 계정 영구 정지
- 법 집행 기관 신고
- 관련 플랫폼 공유를 통한 재가입 방지
- 형사 고발 협조

### 9.2 이의 제기

부당한 조치라고 판단되는 경우 다음 절차를 통해 이의를 제기할 수 있습니다:

1. 이메일(getposty@gmail.com)로 이의 제기서 제출
2. 7일 이내 재검토 착수
3. 독립적인 검토 후 최종 결정
4. 결과 통보 및 필요시 조치 수정

단, CSAM 관련 위반의 경우 이의 제기가 제한될 수 있습니다.

## 10. 투명성 보고

### 10.1 정기 보고서

회사는 아동 안전 활동에 대한 투명성을 보장하기 위해 연간 보고서를 공개합니다:

- 신고 접수 건수 및 처리 현황
- 위반 사례 및 조치 통계
- 법 집행 기관 협력 현황
- 시스템 개선 사항

### 10.2 지속적 개선

회사는 아동 안전 보호를 위해 지속적으로 노력합니다:

- 최신 기술 및 모범 사례 도입
- 정기적인 정책 검토 및 업데이트
- 외부 전문가 및 기관과의 협력
- 사용자 피드백 반영

## 11. 표준 개정

### 11.1 개정 절차

본 표준은 다음의 경우 개정될 수 있습니다:

- 관련 법률 및 규정의 변경
- 새로운 위협 또는 기술의 출현
- 외부 전문가의 권고
- 서비스 기능의 중대한 변경

### 11.2 개정 공지

표준이 개정되는 경우:

- 시행 최소 7일 전 공지
- 앱 내 알림 및 이메일 통보
- 웹사이트 및 법적 문서 페이지 업데이트
- 중대한 변경사항에 대한 상세 설명 제공

## 12. 연락처 및 리소스

### 12.1 회사 연락처

**Posty AI 아동 안전팀**
- 전담 이메일: childsafety@getposty.com
- 일반 지원: getposty@gmail.com
- 웹사이트: [향후 추가 예정]

### 12.2 외부 리소스

**긴급 신고**
- 경찰청 긴급신고: 112
- 아동학대 신고: 112
- 학교폭력 신고: 117
- 청소년 사이버 상담: 1388

**국내 기관**
- 경찰청 사이버안전국: 182
- 한국인터넷진흥원(KISA): 118
- 아동권리보장원: 1577-1391

**국제 기관**
- National Center for Missing & Exploited Children (NCMEC): www.cybertipline.org
- Internet Watch Foundation (IWF): www.iwf.org.uk
- INHOPE (International Association of Internet Hotlines): www.inhope.org

## 13. 법적 고지

본 아동 안전 표준은 Posty AI 서비스 이용약관 및 개인정보 처리방침과 함께 적용됩니다. 상충되는 내용이 있는 경우, 본 표준이 아동 안전 관련 사항에 대해 우선 적용됩니다.

본 표준은 대한민국 법률에 따라 해석되며, 관련 분쟁은 회사의 본사 소재지를 관할하는 법원의 전속 관할에 따릅니다.

---

**최종 업데이트**: 2025년 10월 21일
**시행일**: 2025년 10월 21일

**본 표준에 대한 문의사항은 childsafety@getposty.com 또는 getposty@gmail.com으로 연락해주시기 바랍니다.**

---

**Posty AI는 모든 아동의 안전과 보호를 최우선으로 생각하며, 안전한 디지털 환경 조성을 위해 최선을 다하겠습니다.**
