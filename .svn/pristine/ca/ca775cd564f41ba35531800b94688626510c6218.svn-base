// AIWriteScreenì—ì„œ ì‚¬ìš©í•  OpenRouter ì„œë¹„ìŠ¤ í›…

import { useState, useCallback } from 'react';
import openRouterService from '../services/openRouterService';
import { saveData, getData, STORAGE_KEYS } from '../utils/storage';

interface UseAIServiceProps {
  onSuccess?: (content: string, hashtags: string[]) => void;
  onError?: (error: Error) => void;
}

export const useAIService = ({ onSuccess, onError }: UseAIServiceProps = {}) => {
  const [isGenerating, setIsGenerating] = useState(false);
  const [generatedContent, setGeneratedContent] = useState('');
  const [hashtags, setHashtags] = useState<string[]>([]);
  const [imageAnalysis, setImageAnalysis] = useState<string>('');
  const [usageStats, setUsageStats] = useState({
    tokensUsed: 0,
    cost: 0,
    model: 'deepseek/deepseek-chat',
  });

  // í…ìŠ¤íŠ¸ ìƒì„±
  const generateContent = useCallback(async (
    prompt: string,
    tone: 'casual' | 'professional' | 'humorous' | 'emotional',
    length: 'short' | 'medium' | 'long',
    platform?: 'instagram' | 'facebook' | 'twitter' | 'linkedin'
  ) => {
    setIsGenerating(true);
    try {
      const result = await openRouterService.generateContent({
        prompt,
        tone,
        length,
        platform,
      });

      setGeneratedContent(result.content);
      setHashtags(result.hashtags);
      setUsageStats({
        tokensUsed: result.tokensUsed || 0,
        cost: result.cost || 0,
        model: result.model,
      });

      // íˆìŠ¤í† ë¦¬ ì €ì¥
      await saveGeneratedContent(result);

      onSuccess?.(result.content, result.hashtags);
    } catch (error) {
      console.error('Generate content error:', error);
      onError?.(error as Error);
      
      // ì˜¤í”„ë¼ì¸ í´ë°±
      const fallbackContent = await generateOfflineContent(prompt, tone, length);
      setGeneratedContent(fallbackContent.content);
      setHashtags(fallbackContent.hashtags);
    } finally {
      setIsGenerating(false);
    }
  }, [onSuccess, onError]);

  // ì´ë¯¸ì§€ ë¶„ì„
  const analyzeImage = useCallback(async (imageBase64: string) => {
    setIsGenerating(true);
    try {
      const result = await openRouterService.analyzeImage({ imageBase64 });
      
      setImageAnalysis(result.description);
      setUsageStats(prev => ({
        tokensUsed: prev.tokensUsed + (result.tokensUsed || 0),
        cost: prev.cost + (result.cost || 0),
        model: result.model,
      }));

      return result;
    } catch (error) {
      console.error('Analyze image error:', error);
      onError?.(error as Error);
      
      // ì˜¤í”„ë¼ì¸ í´ë°±
      return {
        description: 'ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.',
        objects: [],
        mood: 'unknown',
        suggestedContent: ['ë©‹ì§„ ì‚¬ì§„ì´ë„¤ìš”! ì´ ìˆœê°„ì„ ê¸°ë¡í•´ë³´ì„¸ìš”.'],
      };
    } finally {
      setIsGenerating(false);
    }
  }, [onError]);

  // ìƒì„±ëœ ì½˜í…ì¸  ì €ì¥
  const saveGeneratedContent = async (content: any) => {
    try {
      const history = await getData<any[]>(STORAGE_KEYS.GENERATED_CONTENT) || [];
      history.push({
        ...content,
        id: Date.now().toString(),
        createdAt: new Date().toISOString(),
      });
      
      // ìµœê·¼ 100ê°œë§Œ ìœ ì§€
      if (history.length > 100) {
        history.splice(0, history.length - 100);
      }
      
      await saveData(STORAGE_KEYS.GENERATED_CONTENT, history);
    } catch (error) {
      console.error('Save content error:', error);
    }
  };

  // ì˜¤í”„ë¼ì¸ ì½˜í…ì¸  ìƒì„±
  const generateOfflineContent = async (
    prompt: string,
    tone: string,
    length: string
  ) => {
    // ìºì‹œëœ ì½˜í…ì¸ ì—ì„œ ìœ ì‚¬í•œ ê²ƒ ì°¾ê¸°
    const history = await getData<any[]>(STORAGE_KEYS.GENERATED_CONTENT) || [];
    const similar = history.find(item => 
      item.prompt?.includes(prompt.split(' ')[0])
    );

    if (similar) {
      return {
        content: similar.content,
        hashtags: similar.hashtags || [],
      };
    }

    // ê¸°ë³¸ í…œí”Œë¦¿
    const templates = {
      casual: [
        `${prompt}ì— ëŒ€í•œ ì˜¤ëŠ˜ì˜ ìƒê°ì„ ê³µìœ í•´ìš”! ì—¬ëŸ¬ë¶„ì€ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”? ğŸ˜Š`,
        `${prompt} ì´ì•¼ê¸°! ì¼ìƒì˜ ì†Œì†Œí•œ í–‰ë³µì„ ë‚˜ëˆ„ì–´ìš” âœ¨`,
      ],
      professional: [
        `${prompt}ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ê³µìœ í•©ë‹ˆë‹¤. í•¨ê»˜ ì„±ì¥í•˜ëŠ” ì‹œê°„ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤.`,
        `ì˜¤ëŠ˜ì€ ${prompt}ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ë³´ë ¤ í•©ë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì˜ ì˜ê²¬ë„ ë“¤ë ¤ì£¼ì„¸ìš”.`,
      ],
      humorous: [
        `${prompt}? ê·¸ê±° ì œê°€ ì œì¼ ì˜í•˜ëŠ” ê±´ë°ìš”! (ì‚¬ì‹¤ ì˜ ëª¨ë¦„) ğŸ˜…`,
        `${prompt} í•˜ë©´ ë– ì˜¤ë¥´ëŠ” ê²Œ... ìŒ... ì¼ë‹¨ ì›ƒì–´ìš”! ğŸ˜„`,
      ],
      emotional: [
        `${prompt}... ì´ ìˆœê°„ì´ ì°¸ ì†Œì¤‘í•˜ê²Œ ëŠê»´ì ¸ìš”. ğŸ’•`,
        `${prompt}ì„(ë¥¼) í†µí•´ ëŠë‚€ ê°ì •ì„ ì—¬ëŸ¬ë¶„ê³¼ ë‚˜ëˆ„ê³  ì‹¶ì–´ìš”. ğŸŒŸ`,
      ],
    };

    const selectedTemplates = templates[tone] || templates.casual;
    const content = selectedTemplates[Math.floor(Math.random() * selectedTemplates.length)];

    return {
      content,
      hashtags: ['#ì¼ìƒ', '#ì†Œí†µ', '#ê³µê°', `#${prompt.replace(/\s/g, '')}`],
    };
  };

  // ì‚¬ìš©ëŸ‰ í†µê³„ ê°€ì ¸ì˜¤ê¸°
  const getUsageHistory = useCallback(async () => {
    const history = await getData<any[]>(STORAGE_KEYS.GENERATED_CONTENT) || [];
    const totalTokens = history.reduce((sum, item) => sum + (item.tokensUsed || 0), 0);
    const totalCost = history.reduce((sum, item) => sum + (item.cost || 0), 0);
    
    return {
      totalPosts: history.length,
      totalTokens,
      totalCost,
      averageTokensPerPost: history.length > 0 ? totalTokens / history.length : 0,
    };
  }, []);

  // ëª¨ë¸ ë³€ê²½
  const changeModel = useCallback((model: string) => {
    openRouterService.setModel(model);
    setUsageStats(prev => ({ ...prev, model }));
  }, []);

  return {
    isGenerating,
    generatedContent,
    hashtags,
    imageAnalysis,
    usageStats,
    generateContent,
    analyzeImage,
    getUsageHistory,
    changeModel,
  };
};